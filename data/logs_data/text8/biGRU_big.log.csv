Starting training ...
Starting Compression ...
Starting training ...
Starting Compression ...
/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Using TensorFlow backend.
/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
Traceback (most recent call last):
  File "compressor.py", line 202, in <module>
    main()
  File "compressor.py", line 164, in main
    predict_lstm(X, Y, Y_original, timesteps, batch_size, alphabet_size, args.model_name)
  File "compressor.py", line 69, in predict_lstm
    model.load_weights(args.model_weights_file)
  File "/src/keras/engine/network.py", line 1157, in load_weights
    with h5py.File(filepath, mode='r') as f:
  File "/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py", line 312, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py", line 142, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 78, in h5py.h5f.open
OSError: Unable to open file (unable to open file: name = '../data/trained_models/text8/biGRU_big.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
Command exited with non-zero status 1
	Command being timed: "python compressor.py -data ../data/processed_files_test/text8.npy -data_params ../data/processed_files_test/text8.param.json -model ../data/trained_models/text8/biGRU_big.hdf5 -model_name biGRU_big -output ../data/compressed/text8/biGRU_big.compressed -batch_size 10000"
	User time (seconds): 35.50
	System time (seconds): 39.71
	Percent of CPU this job got: 122%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 1:01.23
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 27306288
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 28357290
	Voluntary context switches: 302
	Involuntary context switches: 209
	Swaps: 0
	File system inputs: 0
	File system outputs: 16
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 1
/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Using TensorFlow backend.
Traceback (most recent call last):
  File "decompressor.py", line 184, in <module>
    main()
  File "decompressor.py", line 153, in main
    f = open(args.input_file_prefix+'.combined','rb')
FileNotFoundError: [Errno 2] No such file or directory: '../data/compressed/text8/biGRU_big.compressed.combined'
Command exited with non-zero status 1
	Command being timed: "python decompressor.py -output ../data/compressed/text8/biGRU_big.reconstructed.txt -model ../data/trained_models/text8/biGRU_big.hdf5 -model_name biGRU_big -input_file_prefix ../data/compressed/text8/biGRU_big.compressed -batch_size 10000"
	User time (seconds): 1.92
	System time (seconds): 0.22
	Percent of CPU this job got: 100%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.15
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 254332
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 68190
	Voluntary context switches: 27
	Involuntary context switches: 4
	Swaps: 0
	File system inputs: 0
	File system outputs: 8
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 1
Starting training ...
0;1.868933062735242
1;1.7836544298223325
2;1.7751673392538279
3;1.7725699135040762
4;1.7733330388976187
Starting training ...
0;1.9093488376754562
1;1.7666480363286898
2;1.745315456393799
3;1.7350778849365924
4;1.7287398307009196
5;1.7245281341365057
6;1.721446072351164
7;1.7190029297783596
8;1.7172296808052485
9;1.7155870203610242
10;1.7143897862206652
11;1.7134974104327652
